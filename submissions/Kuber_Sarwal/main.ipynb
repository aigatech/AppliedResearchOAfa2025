{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharko123/AppliedResearchOAfa2025/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bdd9e48e",
      "metadata": {
        "id": "bdd9e48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19699aa0-5787-47d6-dd15-c3b8e9acda67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at dima806/music_genres_classification were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at dima806/music_genres_classification and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import tempfile\n",
        "import os\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
        "import torch\n",
        "import librosa\n",
        "\n",
        "pipe = pipeline(\"audio-classification\", model=\"dima806/music_genres_classification\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62Pii4qBokpF",
        "outputId": "4c649168-2f35-4051-de28-df091ed5fa80"
      },
      "id": "62Pii4qBokpF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_files(uploaded_files):\n",
        "    if uploaded_files:\n",
        "        results =[]\n",
        "        path = uploaded_files.name\n",
        "        y, sr = librosa.load(path, sr=16000)  # waveform as np.ndarray\n",
        "        res = pipe(y, sampling_rate=sr)\n",
        "        top_label = max(res, key=lambda x: x['score'])['label']\n",
        "        results.append(f\"Estimated Genre: {top_label}\\n\")\n",
        "        bpm = estimate_bpm(path)\n",
        "        embedding = get_embedding(path)\n",
        "        results.append(f\"Estimated BPM: {bpm}\\n\")\n",
        "        results.append(f\"Embedding: {embedding[:10]}\\n\") #only printing first 10 values of embedding array\n",
        "        key = get_key(path)\n",
        "        results.append(f\"Estimated Key: {key}\\n\")\n",
        "\n",
        "        #similarity checker\n",
        "        min = 1000000000;\n",
        "        for row in ds:\n",
        "          if row['bpm'] is None or row['key'] is None:\n",
        "            continue  # skip rows with missing data\n",
        "          score = similarity_score(bpm, row['bpm'], key, row['key'])\n",
        "          if score < min:\n",
        "            best_row = row\n",
        "            min = score\n",
        "        results.append(f\"Best Match: {best_row['main_caption']}\\n\")\n",
        "        results.append(f\"Best Match File Location: {best_row['location']}\\n\")\n",
        "\n",
        "        return \"\\n\".join(results)\n"
      ],
      "metadata": {
        "id": "ij0GbOVidrS7"
      },
      "id": "ij0GbOVidrS7",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPD_HC5EpLqp",
        "outputId": "94337f07-0532-4b0e-e658-04f1d54811ea"
      },
      "id": "DPD_HC5EpLqp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=16000)\n",
        "    chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    mean_chroma = np.mean(chromagram, axis=1)\n",
        "    chroma_to_key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'] #map the chroma value to a key from this list\n",
        "    estimated_key_index = np.argmax(mean_chroma)\n",
        "    estimated_key = chroma_to_key[estimated_key_index]\n",
        "    return estimated_key\n",
        "def get_embedding(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=16000) #auto sampling rate of 16000\n",
        "    input_values = feature_extractor(y, sampling_rate=sr, return_tensors=\"pt\").input_values\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(input_values).last_hidden_state.mean(dim=1) # generate embeddings using HG model\n",
        "    return embeddings[0].numpy()\n",
        "\n",
        "def estimate_bpm(audio_path): #simple BPM calculator\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    print(tempo)\n",
        "    return round(tempo[0], 2)"
      ],
      "metadata": {
        "id": "AkykLRiYpzSU"
      },
      "id": "AkykLRiYpzSU",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_score(bpm, bpm1, key, key1):\n",
        "  key_score = 1 if str(key) == str(key1) else 0\n",
        "  return (bpm - bpm1)*0.3 + key_score*0.7 #added weights becuase similar keys is more likely and important than similar BPMs. BPMs also range more."
      ],
      "metadata": {
        "id": "320-hPHKxwTx"
      },
      "id": "320-hPHKxwTx",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"amaai-lab/MusicBench\",split=\"train\", streaming=True) #dataset of other song BPM and keys to compare to and see which is similar"
      ],
      "metadata": {
        "id": "iqEuXKTFuKaF"
      },
      "id": "iqEuXKTFuKaF",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface( #gr interface for UI of uploading files\n",
        "    fn=classify_files,\n",
        "    inputs=[\n",
        "        gr.File(file_types=[\".mp3\", \".wav\"]),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label = \"Analysis Result\"),\n",
        "    title=\"Music Genre Classifier\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "ZMDwzLl6dklT",
        "outputId": "5dbc6c69-116e-4a9a-fc06-ed4fd3102dfb",
        "collapsed": true
      },
      "id": "ZMDwzLl6dklT",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://d6c6f8f05b1d79d805.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d6c6f8f05b1d79d805.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[95.703125]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d6c6f8f05b1d79d805.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjn-zpe3oEPI"
      },
      "id": "qjn-zpe3oEPI",
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}